{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553d78c0-3241-4143-bbee-6c314fbb0aab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting groq\n  Downloading groq-0.15.0-py3-none-any.whl (109 kB)\nCollecting typing-extensions<5,>=4.10\n  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting httpx<1,>=0.23.0\n  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\nCollecting distro<2,>=1.7.0\n  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\nCollecting sniffio\n  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nCollecting pydantic<3,>=1.9.0\n  Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\nCollecting anyio<5,>=3.5.0\n  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\nCollecting exceptiongroup>=1.0.2\n  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->groq) (3.3)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->groq) (2021.10.8)\nCollecting httpcore==1.*\n  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\nCollecting h11<0.15,>=0.13\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting pydantic-core==2.27.2\n  Downloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\nInstalling collected packages: typing-extensions, sniffio, h11, exceptiongroup, pydantic-core, httpcore, anyio, annotated-types, pydantic, httpx, distro, groq\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-787afcc0-053e-40f1-9bfc-708dad961890\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: distro\n    Found existing installation: distro 1.4.0\n    Not uninstalling distro at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-787afcc0-053e-40f1-9bfc-708dad961890\n    Can't uninstall 'distro'. No files were found to uninstall.\nSuccessfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 exceptiongroup-1.2.2 groq-0.15.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 pydantic-2.10.5 pydantic-core-2.27.2 sniffio-1.3.1 typing-extensions-4.12.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b2d064-3f31-4665-9f93-85a6f89d093e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GROQ_API_KEY=\"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\"\n"
     ]
    }
   ],
   "source": [
    "%set_env GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c9c9bfd-b0bf-4166-8c38-7635bfbdbe91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: {'SHELL': '/bin/bash',\n 'PIP_NO_INPUT': '1',\n 'SUDO_GID': '0',\n 'PYTHONHASHSEED': '0',\n 'DISABLE_LOCAL_FILESYSTEM': 'false',\n 'JAVA_HOME': '/usr/lib/jvm/zulu8-ca-amd64/jre/',\n 'MLFLOW_PYTHON_EXECUTABLE': '/databricks/spark/scripts/mlflow_python.sh',\n 'JAVA_OPTS': ' -Djava.io.tmpdir=/local_disk0/tmp -XX:-OmitStackTraceInFastThrow -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true   -Ddatabricks.serviceName=driver-1 -Xms7254m -Xmx7254m -Dspark.ui.port=40001 -Dspark.executor.extraJavaOptions=\"-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true   -Ddatabricks.serviceName=spark-executor-1\" -Dspark.executor.memory=8278m -Dspark.executor.extraClassPath=/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*',\n 'SUDO_COMMAND': '/usr/bin/lxc-attach -n 0113-132359-ef44u2nk_10_172_191_33 -- env DB_HOME=/databricks CLUSTER_DB_HOME=/databricks bash -l -c bash ${DB_HOME:-/home/ubuntu/databricks}/spark/scripts/start_chauffeur.sh /tmp/chauffeur-env.sh',\n 'SUDO_USER': 'root',\n 'DATA_SECURITY_MODE': 'LEGACY_SINGLE_USER_STANDARD',\n 'PWD': '/databricks/driver',\n 'LOGNAME': 'root',\n 'DB_HOME': '/databricks',\n 'KOALAS_USAGE_LOGGER': 'pyspark.databricks.koalas.usage_logger',\n 'PYARROW_IGNORE_TIMEZONE': '1',\n 'container': 'lxc',\n 'HIVE_HOME': '/home/ubuntu/hive-0.9.0-bin',\n 'DRIVER_PID_FILE': '/tmp/driver-daemon.pid',\n 'HOME': '/root',\n 'DEFAULT_DATABRICKS_ROOT_VIRTUALENV_ENV': '/databricks/python3',\n 'LANG': 'C.UTF-8',\n 'MLFLOW_TRACKING_URI': 'databricks',\n 'R_LIBS': '/databricks/spark/R/lib:/local_disk0/.ephemeral_nfs/cluster_libraries/r',\n 'VIRTUAL_ENV': '/local_disk0/.ephemeral_nfs/envs/pythonEnv-787afcc0-053e-40f1-9bfc-708dad961890',\n 'DATABRICKS_CLUSTER_LIBS_R_ROOT_DIR': 'r',\n 'CLUSTER_DB_HOME': '/databricks',\n 'PYSPARK_GATEWAY_SECRET': '<hidden>',\n 'DATABRICKS_RUNTIME_VERSION': '12.2',\n 'PYSPARK_PYTHON': '/databricks/python/bin/python',\n 'DATABRICKS_ROOT_VIRTUALENV_ENV': '/databricks/python3',\n 'PYTHONPATH': '/databricks/spark/python:/databricks/spark/python/lib/py4j-0.10.9.5-src.zip:/databricks/jars/spark--driver--driver-spark_3.3_2.12_deploy.jar:/WSFS_NOTEBOOK_DIR:/databricks/spark/python:/databricks/python_shell',\n 'TERM': 'xterm-color',\n 'USER': 'root',\n 'SPARK_PUBLIC_DNS': '10.172.191.33',\n 'SPARK_LOCAL_DIRS': '/local_disk0',\n 'PINNED_THREAD_MODE': 'true',\n 'SHLVL': '0',\n 'MASTER': 'local[8]',\n 'SPARK_HOME': '/databricks/spark',\n 'SPARK_LOCAL_IP': '10.172.191.33',\n 'MLFLOW_CONDA_HOME': '/databricks/conda',\n 'PYSPARK_GATEWAY_PORT': '44749',\n 'MPLBACKEND': 'AGG',\n 'CLASSPATH': '/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/log4j/driver:/databricks/hive/conf:/databricks/spark/dbconf/hadoop:/databricks/jars/*',\n 'SPARK_CONF_DIR': '/databricks/spark/conf',\n 'SPARK_DIST_CLASSPATH': '/databricks/spark/dbconf/log4j/driver:/databricks/jars/*',\n 'PS1': '(pythonEnv-787afcc0-053e-40f1-9bfc-708dad961890) ',\n 'PYENV_ROOT': '/databricks/.pyenv',\n 'ENABLE_IPTABLES': 'false',\n 'JUPYTER_WIDGETS_ECHO': '1',\n 'DATABRICKS_LIBS_NFS_ROOT_PATH': '/local_disk0/.ephemeral_nfs',\n 'SPARK_ENV_LOADED': '1',\n 'DATABRICKS_CLUSTER_LIBS_ROOT_DIR': 'cluster_libraries',\n 'PATH': '/local_disk0/.ephemeral_nfs/envs/pythonEnv-787afcc0-053e-40f1-9bfc-708dad961890/bin:/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin:/databricks/.pyenv/bin:/usr/local/nvidia/bin:/databricks/python3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin',\n 'DATABRICKS_LIBS_NFS_ROOT_DIR': '.ephemeral_nfs',\n 'SUDO_UID': '0',\n 'DATABRICKS_CLUSTER_LIBS_PYTHON_ROOT_DIR': 'python',\n 'SPARK_SCALA_VERSION': '2.12',\n 'MAIL': '/var/mail/root',\n 'SCALA_VERSION': '2.10',\n 'LOW_PRIVILEGED_LIBRARY_INSTALLATION_USER': 'libraries',\n 'OLDPWD': '/databricks/chauffeur',\n 'SPARK_WORKER_MEMORY': '10348m',\n 'PYDEVD_USE_FRAME_EVAL': 'NO',\n 'SPARK_AUTH_SOCKET_TIMEOUT': '15',\n 'SPARK_BUFFER_SIZE': '65536',\n 'CLICOLOR': '1',\n 'PAGER': 'cat',\n 'GIT_PAGER': 'cat',\n 'GROQ_API_KEY': '<hidden>'}"
     ]
    }
   ],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de429286-dc54-4123-b1d3-08b7b9f0ef78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are essential for various applications in natural language processing (NLP) and have numerous benefits. Here are some reasons why fast language models are important:\n\n1. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, providing a seamless and interactive experience. This is particularly important for real-time applications such as chatbots, voice assistants, and language translation software.\n2. **Efficient Processing**: Fast language models can process large volumes of text data quickly, making them ideal for applications that involve text analysis, sentiment analysis, and information retrieval. This efficiency is crucial for applications that require rapid processing of large datasets.\n3. **Scalability**: Fast language models can handle a large number of concurrent requests, making them suitable for large-scale applications such as language translation platforms, text summarization services, and sentiment analysis tools.\n4. **Real-Time Applications**: Fast language models are essential for real-time applications such as:\n\t* Live language translation\n\t* Real-time text analysis\n\t* Sentiment analysis for social media monitoring\n\t* Chatbots and virtual assistants\n5. **Reduced Latency**: Fast language models minimize latency, which is critical for applications that require immediate responses, such as:\n\t* Voice assistants (e.g., Siri, Alexa)\n\t* Language translation apps (e.g., Google Translate)\n\t* Real-time text analysis tools\n6. **Cost Savings**: Fast language models can reduce computational costs by minimizing the time and resources required for processing text data. This can lead to significant cost savings, especially for large-scale applications.\n7. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by providing faster and more efficient services, improving user engagement, and increasing customer satisfaction.\n8. **Enhanced Accuracy**: Fast language models can be trained on larger datasets, which can lead to improved accuracy and better performance in various NLP tasks, such as language translation, text classification, and sentiment analysis.\n9. **Support for Multimodal Interaction**: Fast language models can facilitate multimodal interaction, enabling users to interact with applications using multiple modes, such as voice, text, and gesture.\n10. **Future-Proofing**: As the demand for NLP applications continues to grow, fast language models will play a crucial role in supporting the development of more sophisticated and efficient NLP systems.\n\nTo achieve fast language models, researchers and developers employ various techniques, such as:\n\n1. **Model pruning**: Reducing the size of language models to improve inference speed.\n2. **Knowledge distillation**: Transferring knowledge from large models to smaller ones.\n3. **Quantization**: Representing model weights and activations using lower-precision data types.\n4. **Parallelization**: Distributing computation across multiple processors or GPUs.\n5. **Optimized algorithms**: Developing algorithms that are optimized for specific hardware architectures.\n\nBy leveraging these techniques, fast language models can provide numerous benefits, enabling organizations to develop more efficient, scalable, and accurate NLP applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "groq_inference",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
